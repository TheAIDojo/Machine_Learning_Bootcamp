{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mh4fYe9vvuk"
   },
   "source": [
    "# Model Evaluation\n",
    "\n",
    "<!--<badge>--><a href=\"https://colab.research.google.com/github/TheAIDojo/Machine_Learning_Bootcamp/blob/main/Week 03 - Machine Learning Algorithms/3- Evaluation_Metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><!--</badge>-->\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrP6gOUsaVsy"
   },
   "source": [
    "## Classifier Evaluation\n",
    "\n",
    "### True Positive (TP) \n",
    "\n",
    "The predicted value matches the actual value\n",
    "The actual value was positive and the model predicted a positive value\n",
    "\n",
    "### True Negative (TN) \n",
    "\n",
    "The predicted value matches the actual value\n",
    "The actual value was negative and the model predicted a negative value\n",
    "\n",
    "### False Positive (FP) – Type 1 error\n",
    "\n",
    "The predicted value was falsely predicted\n",
    "The actual value was negative but the model predicted a positive value\n",
    "Also known as the Type 1 error\n",
    "\n",
    "### False Negative (FN) – Type 2 error\n",
    "\n",
    "The predicted value was falsely predicted\n",
    "The actual value was positive but the model predicted a negative value\n",
    "Also known as the Type 2 error\n",
    "\n",
    "### Precision\n",
    "Precision is a good measure to determine, when the costs of False Positive is high. For instance, email spam detection. In email spam detection, a false positive means that an email that is non-spam (actual negative) has been identified as spam (predicted spam). The email user might lose important emails if the precision is not high for the spam detection model.\n",
    "\n",
    "$$Precision = \\dfrac{TP}{TP + FP}$$\n",
    "\n",
    "### Recall\n",
    "Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative.\n",
    "in sick patient detection. If a sick patient (Actual Positive) goes through the test and predicted as not sick (Predicted Negative). The cost associated with False Negative will be extremely high if the sickness is contagious.\n",
    "\n",
    "$$Recall = \\dfrac{TP}{TP + FN}$$\n",
    "\n",
    "### F1 score\n",
    "F1 Score might be a better measure to use if we need to seek a balance between Precision and Recall AND there is an uneven class distribution (large number of Actual Negatives).\n",
    "\n",
    "$$F1 = 2 \\cdot \\dfrac{Precision \\cdot Recall}{Precision + Recall}$$\n",
    "\n",
    "### Confusion Matrix\n",
    "A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by the machine learning model. This gives us a holistic view of how well our classification model is performing and what kinds of errors it is making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WVfD0etJidZq"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model, metrics, datasets, model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LqNVHlaikt4"
   },
   "outputs": [],
   "source": [
    "x, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    x, y, test_size=0.1, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ti3WlBgD40JL",
    "outputId": "4eeff02c-2a57-4677-bc0a-bcf6ff385736"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr = linear_model.LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "lgr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "nevs86s-i-t0",
    "outputId": "5bce484c-8289-4652-d4fd-5eff58025937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.9649122807017544\n",
      "True Positive: 35\n",
      "True Negative: 20\n",
      "False Positive: 1\n",
      "False Negative: 1\n",
      "Precision Score: 0.9722222222222222\n",
      "Precision Score Manual: 0.9722222222222222\n",
      "Recall Score: 0.9722222222222222\n",
      "Recall Score Manual: 0.9722222222222222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7feff88f4ba8>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = lgr.predict(x_test)\n",
    "print(\"Accuracy Score:\", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "cf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "tp, tn, fp, fn = cf_matrix[1, 1], cf_matrix[0, 0], cf_matrix[0, 1], cf_matrix[1, 0]\n",
    "print(\"True Positive:\", tp)\n",
    "print(\"True Negative:\", tn)\n",
    "print(\"False Positive:\", fp)\n",
    "print(\"False Negative:\", fn)\n",
    "\n",
    "precision1 = metrics.precision_score(y_test, y_pred)\n",
    "precision2 = tp / (tp + fp)\n",
    "\n",
    "print(\"Precision Score:\", precision1)\n",
    "print(\"Precision Score Manual:\", precision2)\n",
    "\n",
    "recall1 = metrics.recall_score(y_test, y_pred)\n",
    "recall2 = tp / (tp + fn)\n",
    "print(\"Recall Score:\", recall1)\n",
    "print(\"Recall Score Manual:\", recall2)\n",
    "\n",
    "\n",
    "metrics.plot_confusion_matrix(lgr, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49Zi7e-89fwb"
   },
   "source": [
    "## Regression Metrics\n",
    "\n",
    "### Mean Squared Error\n",
    "\n",
    "MSE is the average of the squared error that is used as the loss function for least squares regression: It is the sum, over all the data points, of the square of the difference between the predicted and actual target variables, divided by the number of data points.\n",
    "\n",
    "$$mse = 1/m \\sum_{i=0}^{m} (\\hat{y_i} - y_i)^2$$\n",
    "\n",
    "Where m is the total number of examples being tested, and $\\hat{y}$ is the predicted label while $y$ is the actual label\n",
    "\n",
    "### Mean Absolute Error\n",
    "\n",
    "MAE is the average of the absolue errors that is used as the loss function for  regression: It is the sum, over all the data points, of the absolute of the difference between the predicted and actual target variables, divided by the number of data points.\n",
    "\n",
    "$$mae = 1/m \\sum_{i=0}^{m} |\\hat{y_i} - y_i|$$\n",
    "\n",
    "Where m is the total number of examples being tested, and $\\hat{y}$ is the predicted label while $y$ is the actual label\n",
    "\n",
    "\n",
    "### $R^2$ score\n",
    "the $R^2$ score varies between 0 and 100%. It is closely related to the MSE .\n",
    "\n",
    "if it is 100%, the two variables are perfectly correlated, i.e., with no variance at all. A low value would show a low level of correlation, meaning a regression model that is not valid, but not in all cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92KHMKxH6n72"
   },
   "outputs": [],
   "source": [
    "x, y = datasets.load_boston(return_X_y=True)\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    x, y, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOOfCGA3nH_e",
    "outputId": "5a1e0ef1-e21e-4c5e-b5ad-d05059ea95e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lnr = linear_model.LinearRegression()\n",
    "lnr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PxpRftWOnMoV",
    "outputId": "9ef31b05-0a80-4240-c858-e56d07006ce5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 14.99585287658254\n",
      "Mean Absolute Error: 2.8342104578589455\n",
      "R2 Score: 0.7598135533532491\n"
     ]
    }
   ],
   "source": [
    "y_pred = lnr.predict(x_test)\n",
    "print(\"Mean Squared Error:\", metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"Mean Absolute Error:\", metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"R2 Score:\", metrics.r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Evaluation_Metrics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}