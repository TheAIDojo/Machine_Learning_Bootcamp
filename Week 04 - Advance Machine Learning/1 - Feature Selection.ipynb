{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hd4Lz8wkfcdj"
   },
   "source": [
    "# Feature Selection\n",
    "\n",
    "\n",
    "<!--<badge>--><a href=\"https://colab.research.google.com/github/TheAIDojo/Machine_Learning_Bootcamp/blob/main/Week 04 - Advance Machine Learning/1 - Feature Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><!--</badge>-->\n",
    "\n",
    "Feature selection is a process where you automatically or manually select those features in your data that contribute most to the prediction variable or output in which you are interested.\n",
    "\n",
    "There are many ways to perform feature selection. Some methods include:\n",
    "\n",
    "- Using a correlation matrix to select features that are highly correlated with the output variable\n",
    "- Using a statistical tests (e.g., $x^2$) to measure the statistical significance of each feature in relation to the label. \n",
    "- Using a recursive feature elimination algorithm to automatically select features that are most relevant to the output variable\n",
    "\n",
    "Feature selection is important in machine learning because it can help you reduce the amount of data you need to work with, which in turn can reduce the amount of time and resources required to train and tune your machine learning model. Additionally, by selecting only the most relevant features, you can improve the interpretability of your machine learning model and make overfitting less likley to occure.\n",
    "\n",
    "There are many feature selection techniques supported by Scikit Learn. We will go through some of them and if you wish to learn more visit [Scikit Learn's Documentation](https://scikit-learn.org/stable/modules/feature_selection.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3euJPnU0fcCU"
   },
   "outputs": [],
   "source": [
    "from sklearn import (\n",
    "    datasets,\n",
    "    model_selection,\n",
    "    feature_selection,\n",
    "    svm,\n",
    "    metrics,\n",
    "    pipeline,\n",
    "    preprocessing,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4zwq1k1zfae4",
    "outputId": "74223840-9527-44f7-c474-f40dcb1b865f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load iris dataset\n",
    "x, y = datasets.load_breast_cancer(return_X_y=True)\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5FBvhd5-EBE"
   },
   "source": [
    "## Feature Selection Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZStJ23HkfrE"
   },
   "source": [
    "### Univariate Feature Selection\n",
    "\n",
    "Univariate feature selection works by selecting the best features based on univariate statistical tests. It can be seen as a preprocessing step to an estimator.\n",
    "\n",
    "We will be using the `SelectKBest` class from Scikit Learn which returing the best $k$ features using some scoring method based on a statistical significance test like $x^2$ (chi-square).\n",
    "\n",
    "Scikit Learn includes additional scoring functions like:\n",
    "\n",
    "- For classification: `chi2`, `f_classif`, `mutual_info_classif`\n",
    "- For regression: `f_regression`, `mutual_info_regression`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zdIpHV6nwaEb",
    "outputId": "da8ea4e4-d5fb-4f37-eea6-9461b7a9b4d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the feature selector by selecing the scoring function and the number of features to select\n",
    "feature_selector = feature_selection.SelectKBest(feature_selection.chi2, k=10)\n",
    "\n",
    "# Use fit transform to train the feature selector and return the best 10 features\n",
    "x_new = feature_selector.fit_transform(x, y)\n",
    "\n",
    "# New X will have 10 features instead of 30\n",
    "x_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ei4QcwSF0v6w"
   },
   "source": [
    "## Training & Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "G6JJ70wZ0v6x"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    x_new, y, test_size=0.3, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "szO8ej9U0v6y",
    "outputId": "b497ea9b-99ba-4fd0-a69e-fe6eaad73ce0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on 10 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('model', SVC(max_iter=10, random_state=10))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Training model on {x_train.shape[1]} features\")\n",
    "\n",
    "# Define a Support Vector Machine classifier with default configuration\n",
    "model = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"scaler\", preprocessing.StandardScaler()),\n",
    "        (\"model\", svm.SVC(kernel=\"rbf\", random_state=10, max_iter=10)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train model using the training dataset\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oq-XRDaP0v6z",
    "outputId": "2c0d747a-6e0e-47ae-e877-5285ebdaf2d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7777777777777778\n",
      "Precision: 0.8876404494382022\n",
      "Recall: 0.7383177570093458\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict the testing set to prepare for calculating the metrics\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate and print relevant scores\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred)\n",
    "recall = metrics.recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gkav1r_6QLHz"
   },
   "source": [
    "# Feature selection using Select From Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eF3dd6CnQVuS"
   },
   "source": [
    "[SelectFromModel](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel) is a meta-transformer that can be used alongside any estimator that assigns importance to each feature through a specific attribute (such as coef_, feature_importances_) or via an importance_getter callable after fitting. \n",
    "\n",
    "The features are considered unimportant and removed if the corresponding importance of the feature values are below the provided threshold parameter. \n",
    "\n",
    "Apart from specifying the threshold numerically, there are built-in heuristics for finding a threshold using a string argument. Available heuristics are “mean”, “median” and float multiples of these like “0.1*mean”. \n",
    "\n",
    "In combination with the threshold criteria, one can use the max_features parameter to set a limit on the number of features to select."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQ7k6NsdV216"
   },
   "source": [
    "## Define and Train the Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ks-dw3vT7tx",
    "outputId": "4c423421-a540-4cc8-8614-ba96ce3c6b58"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc = svm.LinearSVC()\n",
    "lsvc.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzkHBxM1V_eN"
   },
   "source": [
    "## Use the Trained Linear Model to Get the Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7YXLQWLUBup",
    "outputId": "870be180-5c1b-4c4d-b713-7f3f9135147b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_selector = feature_selection.SelectFromModel(lsvc, prefit=True)\n",
    "x_new = feature_selector.transform(\n",
    "    x\n",
    ")  # get the best features using the pretrained model\n",
    "x_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dugS7ARWgKE"
   },
   "source": [
    "## Split the Datase to Train and Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "0VRTE-r8UPtb"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    x_new, y, test_size=0.3, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nN_DtPG8Vrc9"
   },
   "source": [
    "## Training & Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9O9CXCCU9ll",
    "outputId": "d0dec91b-ff98-4be6-d71a-5f29778877da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on 8 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('model', SVC(max_iter=10, random_state=10))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Training model on {x_train.shape[1]} features\")\n",
    "\n",
    "# Define a Support Vector Machine classifier with default configuration\n",
    "model = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"scaler\", preprocessing.StandardScaler()),\n",
    "        (\"model\", svm.SVC(kernel=\"rbf\", random_state=10, max_iter=10)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train model using the training dataset\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EH4fPo7eVCF5",
    "outputId": "471791b6-c918-4963-aed8-0dd046ab5d6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9298245614035088\n",
      "Precision: 0.9279279279279279\n",
      "Recall: 0.9626168224299065\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict the testing set to prepare for calculating the metrics\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate and print relevant scores\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred)\n",
    "recall = metrics.recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCF8uyvr5DKS"
   },
   "source": [
    "# Recursive Feature Elimination\n",
    "\n",
    "Given an external estimator that assigns weights to features (e.g., the coefficients/weights of a linear model), the goal of recursive feature elimination (RFE) is to select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through any specific attribute (such as `coef_`, `feature_importances_`). Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l6AXNXt0805y",
    "outputId": "f5ae1bdf-858c-4542-f403-e88bdef48659"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 12)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use a linear kernel because RFE requires a model that has a coef_ or feature_importances_ attributes\n",
    "svc = svm.SVC(kernel=\"linear\")\n",
    "\n",
    "# Define the feature selector by selecing the estimator and the number of features to select, and the number of features to remove in each iteration\n",
    "rfe = feature_selection.RFE(estimator=svc, n_features_to_select=12, step=1)\n",
    "\n",
    "# Use fit transform to train the feature selector and return the best 10 features\n",
    "x_new = rfe.fit_transform(x, y)\n",
    "\n",
    "# New X will have 12 features instead of 30\n",
    "x_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emX3sGCwyc92"
   },
   "source": [
    "## Training & Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "UoVEg8slyZTo"
   },
   "outputs": [],
   "source": [
    "use_pruned_features = True  # @param {type:\"boolean\"}\n",
    "x_final = x_new if use_pruned_features else x\n",
    "\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    x_new, y, test_size=0.3, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fhKL3ElPyuBu",
    "outputId": "860155e7-2d7a-4003-cc80-46b9003dc61c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on 12 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('model', SVC(max_iter=10, random_state=10))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Training model on {x_train.shape[1]} features\")\n",
    "\n",
    "# Define a Support Vector Machine classifier with default configuration\n",
    "model = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"scaler\", preprocessing.StandardScaler()),\n",
    "        (\"model\", svm.SVC(kernel=\"rbf\", random_state=10, max_iter=10)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Train model using the training dataset\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9dusZZULy_Jq",
    "outputId": "41ea1080-e6a6-4ea7-b12a-bf99cf65981e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.935672514619883\n",
      "Precision: 0.9363636363636364\n",
      "Recall: 0.9626168224299065\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict the testing set to prepare for calculating the metrics\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate and print relevant scores\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred)\n",
    "recall = metrics.recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iav2Q9et3SV6"
   },
   "source": [
    "# Recursive Feature Elimination CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4WwtQqk3oDs"
   },
   "source": [
    "Recursive feature elimination with cross-validation to select the number of features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-nAsnPC3UWe",
    "outputId": "667840db-f73b-475a-e585-7f8aa0d9159a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use a linear kernel because RFECV requires a model that has a coef_ or feature_importances_ attributes\n",
    "svc = svm.SVC(kernel=\"linear\")\n",
    "\n",
    "# Define the feature selector by selecing the estimator and the number of features to select, and the score for the features to be selected\n",
    "feature_selector = feature_selection.RFECV(\n",
    "    lsvc, scoring=metrics.make_scorer(metrics.precision_score)\n",
    ")\n",
    "# Use fit transform to train the feature selector\n",
    "feature_selector.fit(x, y)\n",
    "\n",
    "new_x = feature_selector.transform(x)\n",
    "\n",
    "# New X will have 9 features instead of 30\n",
    "new_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "uBFe87Ur3XVK"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    new_x, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j18PyPYG4LiY"
   },
   "source": [
    "## Training & Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AqianVCP3Y0s",
    "outputId": "b2319989-1fc6-431d-8eb0-204cf9b8cc2b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=10).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('model', SVC(max_iter=10, random_state=10))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a Support Vector Machine classifier with default configuration\n",
    "model = pipeline.Pipeline(\n",
    "    [\n",
    "        (\"scaler\", preprocessing.StandardScaler()),\n",
    "        (\"model\", svm.SVC(kernel=\"rbf\", random_state=10, max_iter=10)),\n",
    "    ]\n",
    ")\n",
    "# Train model using the training dataset\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qEF83uCX3dOQ",
    "outputId": "0b999914-1ad7-4cf5-811f-54deace61ebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9210526315789473\n",
      "Precision: 0.9565217391304348\n",
      "Recall: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "# Use the model to predict the testing set to prepare for calculating the metrics\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Calculate and print relevant scores\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred)\n",
    "recall = metrics.recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lA9m72tq3eol"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Hd4Lz8wkfcdj",
    "gkav1r_6QLHz"
   ],
   "name": "1 - Feature Selection.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b667cebad148e7b094a58ee81f940c685de1dd70a003a9ccdca4a5792431bee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}